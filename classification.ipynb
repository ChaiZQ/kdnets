{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    # General\n",
    "    'batchsize': 227,\n",
    "    'shuffle': True,\n",
    "    # Augmentations\n",
    "    'flip': False,\n",
    "    'ascale': True, 'as_min': 0.6667, 'as_max': 1.5,\n",
    "    'rotate': False, 'r_positions': 12, 'test_pos': None,\n",
    "    'translate': True, 't_rate': 0.1,\n",
    "    # Point clouds and kd-trees generation\n",
    "    'steps': 10, # also control the depth of the network\n",
    "    'dim': 3,\n",
    "    'lim': 1,\n",
    "    'det': False,\n",
    "    'gamma': 10.,\n",
    "    # NN options\n",
    "    'input_features': 'all', # 'all' for point coordinates, 'no' for feeding 1's as point features\n",
    "    'n_f': [16, \n",
    "            32,  32,  \n",
    "            64,  64,  \n",
    "            128, 128, \n",
    "            256, 256, \n",
    "            512, 128], # representation sizes\n",
    "    'n_output': 10,\n",
    "    'l2': 1e-3,\n",
    "    'lr': 1e-3,\n",
    "    'n_ens': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path2data = \"./modelnet10.h5\"\n",
    "with h5.File(path2data, 'r') as hf:\n",
    "    train_vertices = np.array(hf.get('train_vertices'))\n",
    "    train_faces = np.array(hf.get('train_faces'))\n",
    "    train_nFaces = np.array(hf.get('train_nFaces'))\n",
    "    train_labels = np.array(hf.get('train_labels'))\n",
    "    test_vertices = np.array(hf.get('test_vertices'))\n",
    "    test_faces = np.array(hf.get('test_faces'))\n",
    "    test_nFaces = np.array(hf.get('test_nFaces'))\n",
    "    test_labels = np.array(hf.get('test_labels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use('gpu0')\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lasagne.layers import InputLayer, ReshapeLayer, NonlinearityLayer, ExpressionLayer\n",
    "from lasagne.layers import ElemwiseSumLayer, ElemwiseMergeLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers.dnn import BatchNormDNNLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "\n",
    "from lasagne.layers import get_output, get_all_params\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "from lasagne.objectives import categorical_crossentropy, categorical_accuracy\n",
    "from lasagne.updates import adam\n",
    "\n",
    "from lib.nn.layers import SharedDotLayer, SPTNormReshapeLayer\n",
    "from lib.nn.utils import dump_weights, load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clouds = T.tensor3(dtype='float32')\n",
    "norms = [T.tensor3(dtype='float32') for step in xrange(config['steps'])]\n",
    "target = T.vector(dtype='int32')\n",
    "\n",
    "KDNet = {}\n",
    "if config['input_features'] == 'no':\n",
    "    KDNet['input'] = InputLayer((None, 1, 2**config['steps']), input_var=clouds)\n",
    "else:\n",
    "    KDNet['input'] = InputLayer((None, 3, 2**config['steps']), input_var=clouds)\n",
    "for i in xrange(config['steps']):\n",
    "    KDNet['norm{}_r'.format(i+1)] = InputLayer((None, 3, 2**(config['steps']-1-i)), input_var=norms[i])\n",
    "    KDNet['norm{}_l'.format(i+1)] = ExpressionLayer(KDNet['norm{}_r'.format(i+1)], lambda X: -X)\n",
    "\n",
    "    KDNet['norm{}_l_X-'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_l'.format(i+1)], '-', 0, config['n_f'][i+1])\n",
    "    KDNet['norm{}_l_Y-'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_l'.format(i+1)], '-', 1, config['n_f'][i+1])\n",
    "    KDNet['norm{}_l_Z-'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_l'.format(i+1)], '-', 2, config['n_f'][i+1])\n",
    "    KDNet['norm{}_l_X+'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_l'.format(i+1)], '+', 0, config['n_f'][i+1])\n",
    "    KDNet['norm{}_l_Y+'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_l'.format(i+1)], '+', 1, config['n_f'][i+1])\n",
    "    KDNet['norm{}_l_Z+'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_l'.format(i+1)], '+', 2, config['n_f'][i+1])\n",
    "    KDNet['norm{}_r_X-'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_r'.format(i+1)], '-', 0, config['n_f'][i+1])\n",
    "    KDNet['norm{}_r_Y-'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_r'.format(i+1)], '-', 1, config['n_f'][i+1])\n",
    "    KDNet['norm{}_r_Z-'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_r'.format(i+1)], '-', 2, config['n_f'][i+1])\n",
    "    KDNet['norm{}_r_X+'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_r'.format(i+1)], '+', 0, config['n_f'][i+1])\n",
    "    KDNet['norm{}_r_Y+'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_r'.format(i+1)], '+', 1, config['n_f'][i+1])\n",
    "    KDNet['norm{}_r_Z+'.format(i+1)] = SPTNormReshapeLayer(KDNet['norm{}_r'.format(i+1)], '+', 2, config['n_f'][i+1])\n",
    "\n",
    "    KDNet['cloud{}'.format(i+1)] = SharedDotLayer(KDNet['input'], config['n_f'][i]) if i == 0 else \\\n",
    "                                   ElemwiseSumLayer([KDNet['cloud{}_l_X-_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_l_Y-_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_l_Z-_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_l_X+_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_l_Y+_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_l_Z+_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_r_X-_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_r_Y-_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_r_Z-_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_r_X+_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_r_Y+_masked'.format(i)],\n",
    "                                                     KDNet['cloud{}_r_Z+_masked'.format(i)]])\n",
    "    KDNet['cloud{}_bn'.format(i+1)] = BatchNormDNNLayer(KDNet['cloud{}'.format(i+1)])\n",
    "    KDNet['cloud{}_relu'.format(i+1)] = NonlinearityLayer(KDNet['cloud{}_bn'.format(i+1)], rectify)\n",
    "\n",
    "    KDNet['cloud{}_r'.format(i+1)] = ExpressionLayer(KDNet['cloud{}_relu'.format(i+1)],\n",
    "                                                     lambda X: X[:, :, 1::2], \n",
    "                                                     (None, config['n_f'][i], 2**(config['steps']-i-1)))\n",
    "    KDNet['cloud{}_l'.format(i+1)] = ExpressionLayer(KDNet['cloud{}_relu'.format(i+1)],\n",
    "                                                     lambda X: X[:, :, ::2], \n",
    "                                                     (None, config['n_f'][i], 2**(config['steps']-i-1)))\n",
    "\n",
    "    KDNet['cloud{}_l_X-'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_l'.format(i+1)], config['n_f'][i+1])\n",
    "    KDNet['cloud{}_l_Y-'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_l'.format(i+1)], config['n_f'][i+1])\n",
    "    KDNet['cloud{}_l_Z-'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_l'.format(i+1)], config['n_f'][i+1])\n",
    "    KDNet['cloud{}_l_X+'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_l'.format(i+1)], config['n_f'][i+1])\n",
    "    KDNet['cloud{}_l_Y+'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_l'.format(i+1)], config['n_f'][i+1])\n",
    "    KDNet['cloud{}_l_Z+'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_l'.format(i+1)], config['n_f'][i+1])\n",
    "    KDNet['cloud{}_r_X-'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_r'.format(i+1)], config['n_f'][i+1],\n",
    "                                                       W=KDNet['cloud{}_l_X-'.format(i+1)].W, \n",
    "                                                       b=KDNet['cloud{}_l_X-'.format(i+1)].b)\n",
    "    KDNet['cloud{}_r_Y-'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_r'.format(i+1)], config['n_f'][i+1],\n",
    "                                                       W=KDNet['cloud{}_l_Y-'.format(i+1)].W, \n",
    "                                                       b=KDNet['cloud{}_l_Y-'.format(i+1)].b)\n",
    "    KDNet['cloud{}_r_Z-'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_r'.format(i+1)], config['n_f'][i+1],\n",
    "                                                       W=KDNet['cloud{}_l_Z-'.format(i+1)].W, \n",
    "                                                       b=KDNet['cloud{}_l_Z-'.format(i+1)].b)\n",
    "    KDNet['cloud{}_r_X+'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_r'.format(i+1)], config['n_f'][i+1],\n",
    "                                                       W=KDNet['cloud{}_l_X+'.format(i+1)].W,\n",
    "                                                       b=KDNet['cloud{}_l_X+'.format(i+1)].b)\n",
    "    KDNet['cloud{}_r_Y+'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_r'.format(i+1)], config['n_f'][i+1],\n",
    "                                                       W=KDNet['cloud{}_l_Y+'.format(i+1)].W,\n",
    "                                                       b=KDNet['cloud{}_l_Y+'.format(i+1)].b)\n",
    "    KDNet['cloud{}_r_Z+'.format(i+1)] = SharedDotLayer(KDNet['cloud{}_r'.format(i+1)], config['n_f'][i+1],\n",
    "                                                       W=KDNet['cloud{}_l_Z+'.format(i+1)].W,\n",
    "                                                       b=KDNet['cloud{}_l_Z+'.format(i+1)].b)\n",
    "\n",
    "    KDNet['cloud{}_l_X-_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_l_X-'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_l_X-'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_l_Y-_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_l_Y-'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_l_Y-'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_l_Z-_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_l_Z-'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_l_Z-'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_l_X+_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_l_X+'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_l_X+'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_l_Y+_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_l_Y+'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_l_Y+'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_l_Z+_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_l_Z+'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_l_Z+'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_r_X-_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_r_X-'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_r_X-'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_r_Y-_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_r_Y-'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_r_Y-'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_r_Z-_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_r_Z-'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_r_Z-'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_r_X+_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_r_X+'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_r_X+'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_r_Y+_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_r_Y+'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_r_Y+'.format(i+1)]], T.mul)\n",
    "    KDNet['cloud{}_r_Z+_masked'.format(i+1)] = ElemwiseMergeLayer([KDNet['cloud{}_r_Z+'.format(i+1)],\n",
    "                                                                   KDNet['norm{}_r_Z+'.format(i+1)]], T.mul)\n",
    "\n",
    "KDNet['cloud_fin'] = ElemwiseSumLayer([KDNet['cloud{}_l_X-_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_l_Y-_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_l_Z-_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_l_X+_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_l_Y+_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_l_Z+_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_r_X-_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_r_Y-_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_r_Z-_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_r_X+_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_r_Y+_masked'.format(config['steps'])],\n",
    "                                       KDNet['cloud{}_r_Z+_masked'.format(config['steps'])]])\n",
    "KDNet['cloud_fin_bn'] = BatchNormDNNLayer(KDNet['cloud_fin'])\n",
    "KDNet['cloud_fin_relu'] = NonlinearityLayer(KDNet['cloud_fin_bn'], rectify)\n",
    "KDNet['cloud_fin_reshape'] = ReshapeLayer(KDNet['cloud_fin_relu'], (-1, config['n_f'][-1]))\n",
    "KDNet['output'] = DenseLayer(KDNet['cloud_fin_reshape'], config['n_output'], nonlinearity=softmax)\n",
    "\n",
    "# Loading weights (optional)\n",
    "# load_weights('./models/RT+AS+TR+1e-3_10.pkl', KDNet['output'])\n",
    "\n",
    "prob = get_output(KDNet['output'])\n",
    "prob_det = get_output(KDNet['output'], deterministic=True)\n",
    "\n",
    "weights = get_all_params(KDNet['output'], trainable=True)\n",
    "l2_pen = regularize_network_params(KDNet['output'], l2)\n",
    "\n",
    "loss = categorical_crossentropy(prob, target).mean() + config['l2']*l2_pen\n",
    "accuracy = categorical_accuracy(prob, target).mean()\n",
    "\n",
    "lr = theano.shared(np.float32(config['lr']))\n",
    "updates = adam(loss, weights, learning_rate=lr)\n",
    "\n",
    "train_fun = theano.function([clouds] + norms + [target], [loss, accuracy], updates=updates)\n",
    "prob_fun = theano.function([clouds] + norms, prob_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.generators.meshgrid import generate_clouds\n",
    "from lib.trees.kdtrees import KDTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(*arrays, **kwargs):\n",
    "    if kwargs['mode'] == 'train':\n",
    "        indices = np.random.choice((len(arrays[2]) - 1), \n",
    "                                   size=(len(arrays[2]) - 1)/kwargs['batchsize']*kwargs['batchsize'])\n",
    "    elif kwargs['mode'] == 'test':\n",
    "        indices = np.arange(len(arrays[2]) - 1)\n",
    "    if kwargs['shuffle']:\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    for start_idx in xrange(0, len(indices), kwargs['batchsize']):\n",
    "        excerpt = indices[start_idx:start_idx + kwargs['batchsize']]\n",
    "        tmp = generate_clouds(excerpt, kwargs['steps'], arrays[0], arrays[1], arrays[2])\n",
    "        \n",
    "        if kwargs['flip']:\n",
    "            flip = np.random.random(size=(len(tmp), 2, 1))\n",
    "            flip[flip >= 0.5] = 1.\n",
    "            flip[flip < 0.5] = -1.\n",
    "            tmp[:, :2] *= flip\n",
    "        \n",
    "        if kwargs['ascale']:\n",
    "            tmp *= (kwargs['as_min'] + (kwargs['as_max'] - kwargs['as_min'])*np.random.random(size=(len(tmp), kwargs['dim'], 1)))\n",
    "            tmp /= np.fabs(tmp).max(axis=(1, 2), keepdims=True)\n",
    "            \n",
    "        if kwargs['rotate']:\n",
    "            r = np.sqrt((tmp[:, :2]**2).sum(axis=1))\n",
    "            coss = tmp[:, 0]/r\n",
    "            sins = tmp[:, 1]/r\n",
    "            \n",
    "            if kwargs['test_pos'] is not None:\n",
    "                alpha = 2*np.pi*kwargs['test_pos']/kwargs['r_positions']\n",
    "            else:\n",
    "                alpha = 2*np.pi*np.random.randint(0, kwargs['r_positions'], (len(tmp), 1))/kwargs['positions']\n",
    "                \n",
    "            cosr = np.cos(alpha)\n",
    "            sinr = np.sin(alpha)\n",
    "            cos = coss*cosr - sins*sinr\n",
    "            sin = sins*cosr + sinr*coss\n",
    "            tmp[:, 0] = r*cos\n",
    "            tmp[:, 1] = r*sin\n",
    "            \n",
    "        if kwargs['translate']:\n",
    "            mins = tmp.min(axis=2, keepdims=True)\n",
    "            maxs = tmp.max(axis=2, keepdims=True)\n",
    "            rngs = maxs - mins\n",
    "            tmp += kwargs['t_rate']*(np.random.random(size=(len(tmp), kwargs['dim'], 1)) - 0.5)*rngs\n",
    "        \n",
    "        trees_data = KDTrees(tmp, dim=kwargs['dim'], steps=kwargs['steps'], \n",
    "                             lim=kwargs['lim'], det=kwargs['det'], gamma=kwargs['gamma'])\n",
    "            \n",
    "        sortings, normals = trees_data['sortings'], trees_data['normals']\n",
    "        \n",
    "        if kwargs['input_features'] == 'all':\n",
    "            clouds = np.empty((len(excerpt), kwargs['dim'], 2**kwargs['steps']), dtype=np.float32)\n",
    "            for i, srt in enumerate(sortings):\n",
    "                clouds[i] = tmp[i, :, srt].T\n",
    "        elif kwargs['input_features'] == 'no':\n",
    "            clouds = np.ones((len(excerpt), 1, 2**kwargs['steps']), dtype=np.float32)\n",
    "        \n",
    "        if kwargs['mode'] == 'train':\n",
    "            yield [clouds] + normals[::-1] + [arrays[3][excerpt]]\n",
    "        if kwargs['mode'] == 'test':\n",
    "            yield [clouds] + normals[::-1] + [excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probs(vertices, faces, nFaces, **kwargs):\n",
    "    prob_sum = np.zeros((len(nFaces)-1, kwargs['n_output']), dtype=np.float32)\n",
    "    for ens in xrange(kwargs['n_ens']):\n",
    "        probability = np.zeros((len(nFaces)-1, kwargs['n_output']), dtype=np.float32)    \n",
    "        for i, batch in enumerate(iterate_minibatches(vertices, faces, nFaces, **kwargs)):\n",
    "            probability[batch[-1]] += prob_fun(batch[0], \n",
    "                                               batch[1], batch[2], batch[3], batch[4], batch[5], \n",
    "                                               batch[6], batch[7], batch[8], batch[9], batch[10])\n",
    "        prob_sum += probability\n",
    "    return prob_sum / kwargs['n_ens']\n",
    "\n",
    "\n",
    "def acc_fun(vertices, faces, nFaces, labels, **kwargs):\n",
    "    predictions = get_probs(vertices, faces, nFaces, **kwargs)\n",
    "    return 100.*(predictions.argmax(axis=1) == labels).sum()/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "from time import time\n",
    "\n",
    "config['mode'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "num_save = 10\n",
    "\n",
    "train_accuracy = np.zeros(num_epochs, dtype=np.float32)\n",
    "test_accuracy = np.zeros(num_save, dtype=np.float32)\n",
    "\n",
    "# lr.set_value(np.float32(1e-4))\n",
    "\n",
    "for epoch in xrange(num_epochs):\n",
    "    train_err = 0.\n",
    "    train_acc = 0.\n",
    "    \n",
    "    start_time = time()\n",
    "    for i, batch in enumerate(iterate_minibatches(train_vertices, train_faces, train_nFaces, train_labels, **config)):\n",
    "        train_err_batch, train_acc_batch = train_fun(batch[0], \n",
    "                                                     batch[1], batch[2], batch[3], batch[4], batch[5], \n",
    "                                                     batch[6], batch[7], batch[8], batch[9], batch[10],\n",
    "                                                     batch[11])\n",
    "        train_err += train_err_batch*len(batch[0])\n",
    "        train_acc += train_acc_batch*len(batch[0])\n",
    "\n",
    "        stdout.write('\\rEpoch progress: {}/{}\\tAccuracy: {:.2f} %\\t\\tLoss: {:.5f}'\n",
    "                     .format(config['batchsize']*(i+1),\n",
    "                     len(train_nFaces)/config['batchsize']*config['batchsize'],\n",
    "                     100*train_acc/(config['batchsize']*(i+1)),\n",
    "                     train_err/(config['batchsize']*(i+1))))\n",
    "        stdout.flush()\n",
    "    stdout.write('\\n')\n",
    "    stdout.flush()\n",
    "        \n",
    "    train_accuracy[epoch] = 100*train_acc/np.float32(config['batchsize']*(i+1))\n",
    "        \n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time() - start_time))\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err/(config['batchsize']*(i+1))))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_accuracy[epoch]))\n",
    "\n",
    "    if (epoch+1) % (num_epochs/num_save) == 0:\n",
    "        config['mode'] = 'test'\n",
    "        test_accuracy[num_save*epoch/num_epochs] = acc_fun(test_vertices, test_faces, test_nFaces, test_labels, **config)\n",
    "        print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_accuracy[num_save*epoch/num_epochs]))\n",
    "        config['mode'] = 'train'\n",
    "        \n",
    "        dump_weights('../RT_AS+TR_10.pkl', KDNet['output'])\n",
    "        print '  Model saved!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.ylim(70, 100)\n",
    "plt.plot(np.arange(1, num_epochs + 1, 1), train_accuracy, label=\"train\")\n",
    "plt.plot(np.arange(0, num_epochs, num_epochs/num_save), test_accuracy, label=\"test\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy, %\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
